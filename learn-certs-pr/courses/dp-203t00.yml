### YamlMime:Course
title: Data Engineering on Microsoft Azure
metadata:
  title: 'Course DP-203T00-A: Data Engineering on Microsoft Azure'
  description: 'Course DP-203T00-A: Data Engineering on Microsoft Azure'
uid: course.dp-203t00
courseNumber: 'DP-203T00-A'
hoursToComplete: 96
iconUrl: /media/learn/certification/course.svg
skillsGained:
- skill: Исследовать варианты вычислений и хранения для рабочих нагрузок инжиниринга данных в Azure
- skill: Выполнять интерактивные запросы с использованием бессерверных пулов SQL
- skill: Выполнять исследование и преобразование данных в Azure Databricks
- skill: Исследовать, преобразовывать и загружать данные в хранилище данных с использованием Apache Spark
- skill: Принимать и загружать данные в хранилище данных
- skill: Преобразовывать данные с помощью Azure Data Factory или Azure Synapse Pipelines
- skill: Интегрировать данные из записных книжек с помощью Azure Data Factory или Azure Synapse Pipelines
- skill: Поддерживать гибридную транзакционную аналитическую обработку (HTAP) с помощью Azure Synapse Link
- skill: Осуществлять комплексное обеспечение безопасности с помощью Azure Synapse Analytics
- skill: Выполнять потоковую обработку в реальном времени с помощью Stream Analytics
- skill: Создавать решение для потоковой обработки с помощью Event Hubs и Azure Databricks
learningPartnersLink: /learn/certifications/partners
locales:
- en
levels:
- intermediate
roles:
- data-engineer
products:
- azure
exams:
- uid: exam.dp-203
summary: |-
  В этом курсе учащиеся познакомятся с инжинирингом данных в его связи с работой с пакетными и работающими в реальном времени аналитическими решениями с использованием технологий платформ данных Azure. Учащиеся поймут основные технологии вычислений и хранения, которые используются для построения аналитического решения. Учащиеся узнают, как интерактивно исследовать данные, хранящиеся в файлах в озере данных. Учащиеся познакомятся с различными техниками получения, которые могут быть использованы для загрузки данных с использованием возможности Apache Spark, имеющейся в Azure Synapse Analytics или Azure Databricks, или узнают, как осуществлять получение с использованием Azure Data Factory или конвейеров Azure Synapse. Учащиеся также познакомятся с различными способами преобразования данных с использованием тех же технологий, что используются для получения данных. Учащиеся поймут важность реализации обеспечения безопасности для обеспечения защиты неактивных и перемещаемых данных. Учащийся затем покажет, как создать работающую в реальном времени аналитическую систему для создания работающих в реальном времени аналитических решений.

  #### Профиль аудитории
  Основная аудитория этого курса — специалисты в области данных, архитекторы данных и специалисты по бизнес-аналитике, желающие узнать об инжиниринге данных или построении аналитических решений с использованием технологий платформ данных, существующих в Microsoft Azure. Вторичная аудитория этого курса — аналитики данных и специалисты по обработке данных, которые работают с аналитическими решениями, построенными на Microsoft Azure.
prerequisitesSection: |-
  Успешные учащиеся начинают этот курс со знанием понятий вычислений cloud и основных понятий данных, а также профессиональным опытом работы с решениями для работы с данными.

  В частности, проходят&#58;

  - AZ-900 - Azure Fundamentals
  - DP-900 - Microsoft Azure Data Fundamentals
outlineSection: |-
  ### Модуль 1&#58; исследование вариантов вычислений и хранения для рабочих нагрузок инжиниринга данных
  В этом модуле дается обзор вариантов технологий вычислений и хранения Azure, которые доступны инженерам данных, занимающимся построением аналитических рабочих нагрузок. В этом модуле рассматриваются способы структурирования озера данных и оптимизации файлов для исследования, потоковой передачи и пакетных нагрузок. Учащиеся узнают, как упорядочить озеро данных в уровни усовершенствования данных во время преобразования файлов в ходе пакетной и потоковой обработки. Затем учащиеся узнают, как создавать индексы для своих наборов данных, например, файлы CSV, JSON и Parquet, и использовать их для возможного ускорения осуществления запросов и загрузки.
  #### Уроки
  - Знакомство с Azure Synapse Analytics
  - Описание Azure Databricks
  - Знакомство с хранилищем Azure Data Lake
  - Описание архитектуры Delta Lake
  - Работа с потоками данных с использованием Azure Stream Analytics

  #### Лабораторная работа &#58; исследование вариантов вычислений и хранения для рабочих нагрузок инжиниринга данных 
  *   Объединение потоковой и пакетной обработки в одном конвейере
  *   Упорядочение озера данных в уровни преобразования файлов
  *   Индексирование хранилища озера данных для ускорения осуществления запросов и загрузки

  После прохождения этого модуля учащиеся смогут&#58;
  - Описывать Azure Synapse Analytics
  - Описывать Azure Databricks
  - Описывать хранилище Azure Data Lake
  - Описывать архитектуру Delta Lake
  - Описывать Azure Stream Analytics

  ### Модуль 2&#58; выполнение интерактивных запросов с использованием бессерверных пулов SQL Azure Synapse Analytics
  В этом модуле учащиеся узнают, как работать с файлами, хранящимися в озере данных и вешних источниках данных с помощью инструкций T-SQL, осуществляемых бессерверным пулом SQL в Azure Synapse Analytics. Студенты запросят файлы Parquet, хранимые в озере данных, а также файлы CSV, хранимые во внешнем хранилище данных. Затем учащиеся создадут группы безопасности Azure Active Directory и принудительно осуществят доступ к файлам в озере данных с помощью контроля доступа на основе ролей (RBAC) и списков контроля доступа (ACLs).
  #### Уроки
  - Исследование возможностей бессерверных пулов SQL Azure Synapse
  - Запрос данных в озере с использованием бессерверных пулов SQL Azure Synapse
  - Создание объектов метаданных в бессерверных пулах SQL Azure Synapse
  - Защита данных и управление пользователями в бессерверных пулах SQL Azure Synapse

  #### Лабораторная работа &#58; выполнение интерактивных запросов с использованием бессерверных пулов SQL
  - Выполнение запроса данных Parquet с помощью бессерверных пулов SQL
  - Создание внешних таблиц для файлов Parquet и CSV
  - Создание представлений с помощью бессерверных пулов SQL
  - Защита доступа к данным в озере данных во время использования бессерверных пулов SQL
  - Настройка безопасности озера данных с использованием контроля доступа на основе ролей (RBAC) и списка контроля доступа

  После прохождения этого модуля учащиеся смогут&#58;
  - Понимать возможности бессерверных пулов SQL Azure Synapse
  - Выполнять запросы данных в озере с использованием бессерверных пулов SQL Azure Synapse
  - Создавать объекты метаданных в бессерверных пулах SQL Azure Synapse
  - Защищать данные и управлять пользователями в бессерверных пулах SQL Azure Synapse


  ### Модуль 3: исследование и преобразование данных в Azure Databricks

  В этом модуле рассказывается, как использовать различные методы Apache Spark DataFrame для исследования и преобразования данных в Azure Databricks. Учащиеся узнают, как выполнять стандартные методы DataFrame для исследования и преобразования данных. Учащиеся также узнают, как выполнять более расширенные задачи, такие как удаление дублирующихся данных, осуществление работы со значениями дат/времени, переименование столбцов и агрегирование данных.

  #### Уроки

  *   Описание Azure Databricks

  *   Осуществление чтения и записи данных в Azure Databricks

  *   Работа с DataFrames в Azure Databricks

  *   Работа с расширенными методами DataFrames в Azure Databricks


  #### Лабораторная работа : исследование и преобразование данных в Azure Databricks

  ####
  *   Использование DataFrames в Azure Databricks для исследования и фильтрации данных
  *   Кэширование DataFrame для более быстрого выполнения последующих запросов
  *   Удаление дублирующихся данных
  *   Работа со значениями дат/времени
  *   Удаление и переименование столбцов DataFrame
  *   Агрегирование данных, хранящихся в DataFrame

  После прохождения этого модуля учащиеся смогут:

  *   Описывать Azure Databricks

  *   Осуществлять чтение и запись данных в Azure Databricks

  *   Работать с DataFrames в Azure Databricks

  *   Работать с расширенными методами DataFrames в Azure Databricks


  ### Модуль 4: исследование, преобразование и загрузка данных в хранилище данных с использованием Apache Spark

  В этом модуле рассказывается, как исследовать данные, хранимые в озере данных, как преобразовывать данные и загружать данные в реляционное хранилище данных. Учащиеся будут исследовать файлы Parquet и JSON и использовать техники для выполнения запроса и преобразования файлов JSON с иерархическими структурами. Затем учащиеся будут использовать Apache Spark для загрузки данных в хранилище данных и соединения данных Parquet в озере данных с данными в выделенном пуле SQL.

  #### Уроки

  *   Понимание инжиниринга больших данных с помощью Apache Spark в Azure Synapse Analytics

  *   Получение данных с помощью записных книжек Apache Spark в Azure Synapse Analytics

  *   Преобразование данных с помощью DataFrames в пулах Apache Spark в Azure Synapse Analytics

  *   Интеграция пулов SQL и Apache Spark в Azure Synapse Analytics


  #### Лабораторная работа : исследование, преобразование и загрузка данных в хранилище данных с использованием Apache Spark

  ####
  *   Выполнение исследования данных в Synapse Studio
  *   Получение данных с помощью записных книжек Spark в Azure Synapse Analytics
  *   Преобразование данных с помощью DataFrames в пулах Spark в Azure Synapse Analytics
  *   Интеграция пулов SQL и Spark в Azure Synapse Analytics

  После прохождения этого модуля учащиеся смогут:

  *   Описывать инжиниринг больших данных с помощью Apache Spark в Azure Synapse Analytics

  *   Получать данные с помощью записных книжек Apache Spark в Azure Synapse Analytics

  *   Преобразовывать данные с помощью DataFrames в пулах Apache Spark в Azure Synapse Analytics

  *   Интегрировать пулы SQL и Apache Spark в Azure Synapse Analytics
  
  ### Модуль 5: прием и загрузка данных в хранилище данных

  В этом модуле рассказывается, как принимать данные в хранилище данных с помощью скриптов T-SQL и конвейеров интеграции Synapse Analytics. Учащиеся узнают, как загружать данные в выделенные пулы SQL Synapse с помощью PolyBase и COPY с использованием T-SQL. Учащиеся также узнают, как использовать управление загрузками вместе с действием «Копировать» в конвейере Azure Synapse для принятия петабайтов данных.

  #### Уроки

  *   Использование лучших практик загрузки данных в Azure Synapse Analytics

  *   Прием петабайтов данных с помощью Azure Data Factory


  #### Лабораторная работа : прием и загрузка данных в хранилище данных

  ####
  *   Выполнение принятия петабайтов данных с помощью Azure Synapse Pipelines
  *   Импорт данных с помощью PolyBase и COPY с использованием T-SQL
  *   Использование лучших практик загрузки данных в Azure Synapse Analytics

  После прохождения этого модуля учащиеся смогут:

  *   Использовать лучшие практики загрузки данных в Azure Synapse Analytics

  *   Принимать петабайты данных с помощью Azure Data Factory


  ### Модуль 6: преобразование данных с помощью Azure Data Factory или Azure Synapse Pipelines

  В этом модуле учащиеся учатся строить конвейеры интеграции данных для принятия из различных источников данных, преобразовывать данные с использованием сопоставления потоков данных и выполнять перемещение данных в один или несколько приемников данных.

  #### Уроки

  *   Интеграция данных с помощью Azure Data Factory или Azure Synapse Pipelines

  *   Безкодовое преобразование в масштабе с помощью Azure Data Factory или Azure Synapse Pipelines


  #### Лабораторная работа : преобразование данных с помощью Azure Data Factory или Azure Synapse Pipelines

  ####
  *   Выполнение безкодовых преобразований в масштабе с помощью Azure Synapse Pipelines
  *   Создание конвейера данных для импорта файлов CSV с неправильным форматом
  *   Создание потоков сопоставления данных

  После прохождения этого модуля учащиеся смогут:

  *   Осуществлять интеграцию данных с помощью Azure Data Factory

  *   Осуществлять безкодовое преобразование в масштабе с помощью Azure Data Factory
  
  ### Модуль 7: осуществление оркестрации перемещения и преобразования данных в Azure Synapse Pipelines

  В этом модуле вы узнаете, как создавать связанные службы и оркестрировать перемещение и преобразование данных с использованием записных книжек в Azure Synapse Pipelines.

  #### Уроки

  *   Оркестрация перемещения и преобразования данных в Azure Data Factory


  #### Лабораторная работа : осуществление оркестрации перемещения и преобразования данных в Azure Synapse Pipelines

  ####
  *   Интеграция данных из записных книжек с помощью Azure Data Factory или Azure Synapse Pipelines

  После прохождения этого модуля учащиеся смогут:

  *   Осуществлять оркестрацию перемещения и преобразования данных в Azure Synapse Pipelines


  ### Модуль 8: комплексное обеспечение безопасности с помощью Azure Synapse Analytics

  В этом модуле учащиеся узнают, как защищать рабочую область Synapse Analytics и ее поддерживающую инфраструктуру. Учащиеся будут рассматривать SQL Active Directory Admin, осуществлять управление правилами брандмауэра IP, осуществлять управление секретами с помощью Azure Key Vault и осуществлять доступ к таким секретам с помощью связанной с Key Vault службой и операций конвейера. Учащиеся поймут, как реализовывать обеспечение безопасности на уровне столбцов и на уровне строк и маскирование данных dynamic во время использования выделенных пулов SQL.

  #### Уроки

  *   Защита хранилища данных в Azure Synapse Analytics

  *   Настройка секретов в Azure Key Vault и управление ими

  *   Реализация контроля соответствия для конфиденциальных данных


  #### Лабораторная работа : комплексное обеспечение безопасности с помощью Azure Synapse Analytics

  ####
  *   Защита поддерживающей инфраструктуры Azure Synapse Analytics
  *   Защита рабочей области Azure Synapse Analytics и управляемых служб
  *   Защита данных рабочей области Azure Synapse Analytics

  После прохождения этого модуля учащиеся смогут:

  *   Обеспечивать защиту хранилища данных в Azure Synapse Analytics

  *   Настраивать секреты в Azure Key Vault и управлять ими

  *   Реализовывать контроль соответствия для конфиденциальных данных
  
  ### Модуль 9: поддержка Hybrid Transactional Analytical Processing (HTAP) с помощью Azure Synapse Link

  В этом модуле учащиеся узнают, как Azure Synapse Link обеспечивает легкое подключение учетной записи Azure Cosmos DB к рабочей области Synapse. Учащиеся поймут, как обеспечивать и настраивать подключение Synapse, как затем запрашивать аналитическое хранилище Azure Cosmos DB с использованием Apache Spark и SQL без сервера.

  #### Уроки

  *   Разработка гибридной транзакционной и аналитической обработки с использованием Azure Synapse Analytics

  *   Настройка Azure Synapse Link с помощью Azure Cosmos DB

  *   Запрашивание Azure Cosmos DB с помощью пулов Apache Spark

  *   Запрашивание Azure Cosmos DB с помощью бессерверных пулов SQL


  #### Лабораторная работа : поддержка Hybrid Transactional Analytical Processing (HTAP) с помощью Azure Synapse Link

  ####
  *   Настраивать Azure Synapse Link с помощью Azure Cosmos DB
  *   Запрашивание Azure Cosmos DB с помощью Apache Spark для Synapse Analytics
  *   Запрашивание Azure Cosmos DB с помощью бессерверного пула SQL для Azure Synapse Analytics

  После прохождения этого модуля учащиеся смогут:

  *   Разрабатывать гибридную транзакционную и аналитическую обработку с использованием Azure Synapse Analytics

  *   Настраивать Azure Synapse Link с помощью Azure Cosmos DB

  *   Запрашивать Azure Cosmos DB с помощью Apache Spark для Azure Synapse Analytics

  *   Запрашивать Azure Cosmos DB с помощью SQL без сервера для Azure Synapse Analytics


  ### Модуль 10: потоковая обработка в реальном времени с помощью Stream Analytics

  В этом модуле учащиеся узнают, как обрабатывать потоковые данные с помощью Azure Stream Analytics. Учащиеся примут данные телеметрии транспортного средства в Event Hubs, затем обработают эти данные в реальном времени с использованием различных оконных функций в Azure Stream Analytics. Учащиеся выведут данные в Azure Synapse Analytics. В завершение учащиеся узнают, как масштабировать задание Stream Analytics для увеличения пропускной способности.

  #### Уроки

  *   Обеспечение надежного обмена сообщениями для приложений Big Data с использованием Azure Event Hubs

  *   Работа с потоками данных с использованием Azure Stream Analytics

  *   Прием потоков данных с использованием Azure Stream Analytics


  #### Лабораторная работа : потоковая обработка в реальном времени с помощью Stream Analytics

  ####
  *   Использование Stream Analytics для обработки в режиме реального времени данных от Event Hubs
  *   Использование оконных функций Stream Analytics для построения агрегатов и вывода в Synapse Analytics
  *   Масштабирование задания Azure Stream Analytics для увеличения пропускной способности с помощью секционирования
  *   Повторное разбиение входных данных потока для оптимизации распараллеливания

  После прохождения этого модуля учащиеся смогут:

  *   Обеспечивать надежный обмен сообщениями для приложений Big Data с использованием Azure Event Hubs

  *   Работать с потоками данных с использованием Azure Stream Analytics

  *   Принимать потоки данных с использованием Azure Stream Analytics

  ### Модуль 11: создание решения для потоковой обработки с помощью Event Hubs и Azure Databricks

  В этом модуле учащиеся узнают, как принимать и обрабатывать потоковые данные в масштабе с помощью Event Hubs и Spark Structured Streaming в Azure Databricks. Учащиеся познакомятся с ключевыми функциями и вариантами использования Structured Streaming. Учащиеся применят скользящие окна для агрегирования блоков данных и применения водяных знаков для удаления устаревших данных. В завершение учащиеся подключатся к Event Hubs для чтения и записи потоков.

  #### Уроки

  *   Обработка потоковых данных с помощью Azure Databricks structured streaming


  #### Лабораторная работа : создание решения для потоковой обработки с помощью Event Hubs и Azure Databricks

  ####
  *   Изучение основных функций и вариантов использования Structured Streaming
  *   Потоковая передача данных из файла и их запись в распределенную файловую систему
  *   Использование скользящих окон для агрегирования блоков данных, а не всех данных
  *   Применение водяных знаков для удаления устаревших данных
  *   Подключение к потокам чтения и записи Event Hubs

  После прохождения этого модуля учащиеся смогут:

  *   Обрабатывать потоковые данные с помощью Azure Databricks structured streaming
